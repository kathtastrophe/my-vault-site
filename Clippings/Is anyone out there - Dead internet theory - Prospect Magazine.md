---
title: "Is anyone out there?"
source: "https://www.prospectmagazine.co.uk/ideas/technology/internet/67864/dead-internet-theory-ai"
author: "James Ball"
published:
created: 2025-03-26
description: "Dead Internet Theory says that you’re the only human left online. It started out as a conspiratorial joke, but it is edging ever closer to reality"
tags:
  - "clippings"
---
The web is being taken over by a global, automated ad fraud system

The idea began to gain traction almost a decade ago, with the “time of death” of the internet typically given as being around 2015 or 2016—but in the years since, reality has begun to mirror this once unserious conspiracy. The complaint of the modern internet is that it is filled with “slop” content, the spiritual successor to email spam. Low-quality content—such as trashy viral images or regurgitated news articles—created by artificial intelligence is filling up social media, search results and anywhere else you might look. But while junk memes are near impossible to avoid, they are just the most visible sign of the AI detritus that is coming to dominate our online worlds.

In reality, the internet is bots all the way down. Automated systems generate fake but clickable content. Bot accounts like and comment, boosting the slop in the algorithms of social media sites and search engines. Clickfarms monetise the whole endeavour, posing as real users with real eyeballs and thus earning advertising revenue. In this way, the web is being taken over by a global, automated ad fraud system, and whether or not any human sees any of it is entirely irrelevant. The things that generate real value for us are being pushed further and further to the margins, unable to compete with this brutal new algorithmic reality.

The most obvious destination for slop is Facebook, a social network that has been seen as dated and perennially naff for at least a decade, but which nonetheless counts more than a quarter of humanity as its users—even if many don’t log in quite as often as they used to.

For a while, the trend was for images of what looked like wood or sand sculptures and their artists, with captions such as “made it with my own hands”. At another point, bizarre images of Jesus were du jour. One image of “shrimp Jesus” portrayed Christianity’s saviour as a crustacean. This was followed by pictures of US veterans, beggars or children looking miserable with birthday cakes, usually in strange locations, captioned with “why do images like this never trend?” The latest fad is for pictures of grotesquely emaciated people holding out begging bowls, often with strange skeleton or snake-like appendages. The nature of the junk memes changes, but it is always bizarre and lacking in any obvious purpose.

The independent journalism startup 404 Media has done more than anyone else to work out what is behind the apparently unstoppable slew of AI-generated slop on Facebook. The answer is a sign of what’s gone wrong on the internet and indicates how difficult it will be to fix: ultimately Facebook is funding the content that is destroying the value of its own network.

Behind the accounts posting slop on Facebook are entrepreneurs, of sorts, working out of countries including India, Vietnam and the Philippines, where internet access is widespread but incomes are relatively low. Here, the advertising revenue from a viral Facebook meme page is much more attractive relative to an average salary than it is in a country such as the UK.

Some users who persistently comment on AI slop appear to have two personalities, effectively because they do. One “persona”—the real person—comments as usual on their local interest groups. But their account, which has been compromised without them noticing, also posts generic, AI-generated comments on thousands of pieces of AI-generated slop. This is a kind of benign hacking, in which bots piggyback on an account, letting the real user go about their business while using it to boost their content—a parasite for the digital era.

The motive is, of course, money. Facebook slop is monetised in two ways. Meta, which owns Facebook, shares revenue from the advertising it shows alongside the content of major creators. This means that if AI meme pages generate a big and apparently real audience on the site, Facebook itself pays the page creators. But if Facebook is the laboratory in which slop developed its strength, it long ago leaked into the wider internet ecosystem. Many pages direct users elsewhere, onto the web proper, where more money can be made. It is here that junk content for junk clicks reaches its natural and inevitable peak.

In his 2008 book *Flat Earth News*, the journalist Nick Davies identified a new scourge of the journalism industry, brought about by the internet era. Junior staff at local and even national newspapers were being asked to generate huge numbers of online stories at a relentless pace.

Instead of going out to speak to people or do original reporting, journalists would be required to produce a story every hour, or even every 45 minutes, by simply rewriting other people’s work. Davies popularised a name for this phenomenon—“churnalism”—and pointed to the obsession of bosses with generating online clicks for advertising revenue as its cause. 

Sixteen years on, newsroom bosses are reaping what they sowed with the race to the bottom, pursuing cheap content to satisfy only the most casual of online browsers. Executives learned that if online clicks are all you care about, most of the journalism can be discarded. Their successors realised something more: the newsroom itself can be thrown away. Instead of having a real media organisation, you can churn out rewrites using ChatGPT and other AI tools, which can even build a credible looking news site itself. 

In a world where ad revenue is all that matters, the first realisation was that journalists were optional. This was followed by the understanding that the news site didn’t need to be real in any meaningful way either; anyone can create something that looks newsy enough to hook people in. There was only one obvious next step: if neither the content nor the site has to be real, why does the audience need to be?

This completes the soulless lifecycle of the modern internet economy. People desperate to earn a meagre living create automated systems that churn out low-quality or outright fake content. Others create dummy accounts to boost and share such content, or fake users to read it. All of this is done to milk some money out of real-world brands. Along the way, it enriches the internet giants that operate all of the machinery.

Real people and our needs have become irrelevant to the business model of the modern internet. If something interests us, our clicks pay just the same as a fake user in a Chinese clickfarm. Good content is relegated to the sidelines, to people who are able and willing to pay for the real thing. Original reported journalism is increasingly siloed behind paywalls that are, themselves, getting ever harder. Everyone else is force-fed slop, because there is no value in giving them anything better.

The journalist and activist Cory Doctorow christened this phenomenon the “enshittification” of the internet, and argued it was an inevitable result of the business model of the modern internet age: hooking people in on a free or subsidised product, getting a monopoly and then starting to extract as much profit from that product as is possible. As consumers, we get hooked on a product—be it a cheap taxi ride, a holiday, food delivery or human connection through social media—that is genuinely too good to be true, because it’s being subsidised by billionaire investors. Then we watch it steadily get worse.

That extends well beyond online browsing. Ridesharing apps such as Uber, Lyft and their competitors captured the private hire market by drastically undercutting the cost of existing taxis, while initially paying drivers at least as much as they had before. Once the market was captured and the old incumbents had given up, first the drivers were screwed by declining incomes, and then customers faced higher prices. The apparently great new service could never have actually lasted in the long term. This story plays out in almost every other venture capital market, from subscription boxes and fast food or grocery delivery, to Airbnb and WeWork. 

The joke of the Dead Internet Theory was that everyone else online might have disappeared, and you could be left alone without noticing. In the decade since the idea caught on, emerging technologies have been harnessed almost as though this is the goal. Humanity has become irrelevant to the business model of the internet, and so we’re getting relegated to the sidelines.

None of the internet giants seem to even see the problem, let alone a way to fix it. Instead of trying to rebuild internet services to their former glory, they are packing in more AI and automation, and, inevitably even more slop. But an internet built for the bots is doomed to fail: in the end the economy is made up of the collective efforts of humans, not anything else.